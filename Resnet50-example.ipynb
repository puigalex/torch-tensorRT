{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://developer.download.nvidia.com/tesla/notebook_assets/nv_logo_torch_trt_resnet_notebook.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Torch-TensorRT Getting Started - ResNet 50"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!nvidia-smi\n",
    "!pip install ipywidgets --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host=files.pythonhosted.org"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cargar Resnet\n",
    "\n",
    "Vamos a cargar el modelo de Resnet directo del hub de modelos pre entrenados que tiene Pytorch por default. Si quieres optimizar tu propio modelo, este paso debes de saltarlo y debes cargar tu modelo a una variable tal como aqui se ve con **resnet50_model** "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "resnet50_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "resnet50_model.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Descargaremos 4 imagenes para pre procesarlas y que esten en el formato en el que resnet50 las requiere"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!mkdir -p ./data\n",
    "!wget  -O ./data/img0.JPG \"https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\"\n",
    "!wget  -O ./data/img1.JPG \"https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\"\n",
    "!wget  -O ./data/img2.JPG \"https://www.artis.nl/media/filer_public_thumbnails/filer_public/00/f1/00f1b6db-fbed-4fef-9ab0-84e944ff11f8/chimpansee_amber_r_1920x1080.jpg__1920x1080_q85_subject_location-923%2C365_subsampling-2.jpg\"\n",
    "!wget  -O ./data/img3.JPG \"https://www.familyhandyman.com/wp-content/uploads/2018/09/How-to-Avoid-Snakes-Slithering-Up-Your-Toilet-shutterstock_780480850.jpg\"\n",
    "\n",
    "!wget  -O ./data/imagenet_class_index.json \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\""
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para poder usar resnet en pytorch se deben de hacer unas transformaciones a las imagenes, la imagenes deben ser normalizadas con una media de [0.485, 0.456, 0.406] y una desviacion de std = [0.229, 0.224, 0.225]\n",
    "\n",
    "Aparte de esto las imagenes deben de tener medidas minimas de 224 de altura y ancho, con los 3 canales de rolor RG B\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i in range(4):\n",
    "    img_path = './data/img%d.JPG'%i\n",
    "    img = Image.open(img_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(img)      \n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "# loading labels    \n",
    "with open(\"./data/imagenet_class_index.json\") as json_file: \n",
    "    d = json.load(json_file)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estas funciones que provee pytorch en su repo son para poder preporcesar las imagenes, generar predicciones y poder correr un benchmark para medir el desempeño de resnet50, en caso de tener tu propio modelo estas funciones se adecuan al modelo en específico que tienes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def rn50_preprocess():\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess\n",
    "\n",
    "# decode the results into ([predicted class, description], probability)\n",
    "def predict(img_path, model, device=\"cuda\"):\n",
    "    img = Image.open(img_path)\n",
    "    preprocess = rn50_preprocess()\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to(device)\n",
    "        model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "        sm_output = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        \n",
    "    ind = torch.argmax(sm_output)\n",
    "    return d[str(ind.item())], sm_output[ind] #([predicted class, description], probability)\n",
    "\n",
    "def benchmark(model, input_shape=(1024, 1, 224, 224), dtype='fp32', nwarmup=50, nruns=10000, device=\"cuda\"):\n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_data = input_data.to(device)\n",
    "    if dtype=='fp16':\n",
    "        input_data = input_data.half()\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            features = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, ave batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    print(\"Output features size:\", features.size())\n",
    "    print('Average batch time: %.2f ms'%(np.mean(timings)*1000))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(4):\n",
    "    img_path = './data/img%d.JPG'%i\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    pred, prob = predict(img_path, resnet50_model)\n",
    "    print('{} - Predicted: {}, Probablility: {}'.format(img_path, pred, prob))\n",
    "\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(img);\n",
    "    plt.axis('off');\n",
    "    plt.title(pred[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model benchmark without Torch-TensorRT\n",
    "model = resnet50_model.eval().to(\"cuda\")\n",
    "benchmark(model, input_shape=(128, 3, 224, 224), nruns=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Primera optimización, torchscript en fp32"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch_tensorrt\n",
    "\n",
    "\n",
    "trt_model_fp32 = torch_tensorrt.compile(model, inputs = [torch_tensorrt.Input((128, 3, 224, 224), dtype=torch.float32)],\n",
    "    enabled_precisions = torch.float32, # Run with FP32\n",
    "    workspace_size = 1 << 22\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtain the average time taken by a batch of input\n",
    "benchmark(trt_model_fp32, input_shape=(128, 3, 224, 224), nruns=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Segunda optimización, FP16"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch_tensorrt\n",
    "\n",
    "# The compiled module will have precision as specified by \"op_precision\".\n",
    "# Here, it will have FP16 precision.\n",
    "trt_model_fp16 = torch_tensorrt.compile(model, inputs = [torch_tensorrt.Input((128, 3, 224, 224), dtype=torch.half)],\n",
    "    enabled_precisions = {torch.half}, \n",
    "    workspace_size = 1 << 22\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtain the average time taken by a batch of input\n",
    "benchmark(trt_model_fp16, input_shape=(128, 3, 224, 224), dtype='fp16', nruns=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.jit.save(trt_model_fp16, \"modelo_optimizado.ts\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelo = torch.load(\"modelo_optimizado.ts\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "benchmark(modelo, input_shape=(128, 3, 224, 224), dtype='fp16', nruns=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark de prueba en CPU\n",
    "Esta celda no es necesaria, solo está aqui por si quieres hacer una comparación de cuanto toma este modelo para correr en CPU vs GPU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "benchmark(model, input_shape=(128, 3, 224, 224), dtype='fp16', nruns=100, device=\"cpu\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('TensorRT': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "interpreter": {
   "hash": "a7ce73d895a8f1312802c732d5e7213d09e3fc765adfbbe00829ed5c21d057e5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}